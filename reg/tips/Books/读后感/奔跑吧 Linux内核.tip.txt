3．请简述在你所熟悉的处理器（比如双核Cortex-A9）中一条存储读写指令的执行全过程。
经典处理器架构的流水线是五级流水线：取指（IF）、译码（ID）、执行（EX）、数据内存访问（MEM）和写回（WB）。

一条存储读写指令的执行全过程很难用一句话来回答。在一个支持超标量和乱序执行技术的处理器当中，一条存储读写指令的执行过程被分解为若干步骤。指令首先进入流水线（pipeline）的前端（Front-End），包括预取（fetch）和译码（decode），经过分发（dispatch）和调度（scheduler）后进入执行单元，最后提交执行结果。所有的指令采用顺序方式（In-Order）通过前端，并采用乱序的方式进行发射，然后乱序执行，最后用顺序方式提交结果，并将最终结果更新到LSQ（Load-Store Queue）部件。LSQ部件是指令流水线的一个执行部件，可以理解为存储子系统的最高层，其上接收来自CPU的存储器指令，其下连接着存储器子系统。其主要功能是将来自CPU的存储器请求发送到存储器子系统，并处理其下存储器子系统的应答数据和消息。



现代处理器在设计上都采用了超标量体系结构（Superscalar ArchitecArchitecture）和乱序执行（Out-of-Order，OOO）技术，极大地提高了处理器计算能力。超标量技术能够在一个时钟周期内执行多个指令，实现指令级的并行，有效提高了ILP（Instruction Level Parallelism）指令级的并行效率，同时也增加了整个cache和memory层次结构的实现难度。
一条存储读写指令的执行全过程很难用一句话来回答。在一个支持超标量和乱序执行技术的处理器当中，一条存储读写指令的执行过程被分解为若干步骤。指令首先进入流水线（pipeline）的前端（Front-End），包括预取（fetch）和译码（decode），经过分发（dispatch）和调度（scheduler）后进入执行单元，最后提交执行结果。所有的指令采用顺序方式（In-Order）通过前端，并采用乱序的方式进行发射，然后乱序执行，最后用顺序方式提交结果，并将最终结果更新到LSQ（Load-Store Queue）部件。LSQ部件是指令流水线的一个执行部件，可以理解为存储子系统的最高层，其上接收来自CPU的存储器指令，其下连接着存储器子系统。其主要功能是将来自CPU的存储器请求发送到存储器子系统，并处理其下存储器子系统的应答数据和消息。
很多程序员对乱序执行的理解有误差。对于一串给定的指令序列，为了提高效率，处理器会找出非真正数据依赖和地址依赖的指令，让它们并行执行。但是在提交执行结果时，是按照指令次序的。总的来说，顺序提交指令，乱序执行，最后顺序提交结果。例如有两条没有数据依赖的数据指令，后面那条指令的读数据先被返回，它的结果也不能先写回到最终寄存器，而是必须等到前一条指令完成之后才可以。
对于读指令，当处理器在等待数据从缓存或者内存返回时，它处于什么状态呢？是等在那不动，还是继续执行别的指令？对于乱序执行的处理器，可以执行后面的指令；对于顺序执行的处理器，会使流水线停顿，直到读取的数据返回。
如图1.1所示，在x86微处理器经典架构中，存储指令从L1指令cache中读取指令，L1指令cache会做指令加载、指令预取、指令预解码，以及分支预测。然后进入Fetch & Decode单元，会把指令解码成macro-ops微操作指令，然后由Dispatch部件分发到Integer Unit或者FloatPoint Unit。Integer Unit由Integer Scheduler和Execution Unit组成，Execution Unit包含算术逻辑单元（arithmetic-logic unit，ALU）和地址生成单元（address generation unit，AGU），在ALU计算完成之后进入AGU，计算有效地址完毕后，将结果发送到LSQ部件。LSQ部件首先根据处理器系统要求的内存一致性（memory consistency）模型确定访问时序，另外LSQ还需要处理存储器指令间的依赖关系，最后LSQ需要准备L1 cache使用的地址，包括有效地址的计算和虚实地址转换，将地址发送到L1 Data Cache中。

图1.1 x86微处理器经典架构图
如图1.2所示，在ARM Cortex-A9处理器中，存储指令首先通过主存储器或者L2 cache加载到L1指令cache中。在指令预取阶段（instruction prefetch stage），主要是做指令预取和分支预测，然后指令通过Instruction Queue队列被送到解码器进行指令的解码工作。解码器（decode）支持两路解码，可以同时解码两条指令。在寄存器重命名阶段（Register rename stage）会做寄存器重命名，避免机器指令不必要的顺序化操作，提高处理器的指令级并行能力。在指令分发阶段（Dispatch stage），这里支持4路猜测发射和乱序执行（Out-of-Order Multi-Issue with Speculation），然后在执行单元（ALU/MUL/FPU/NEON）中乱序执行。存储指令会计算有效地址并发送到内存系统中的LSU部件（Load Store Unit），最终LSU部件会去访问L1数据cache。在ARM中，只有cacheable的内存地址才需要访问cache。



在多处理器环境下，还需要考虑Cache的一致性问题。L1和L2 Cache控制器需要保证cache的一致性，在Cortex-A9中cache的一致性是由MESI协议来实现的。Cortex-A9处理器内置了L1 Cache模块，由SCU（Snoop Control Unit）单元来实现Cache的一致性管理。L2 Cache需要外接芯片（例如PL310）。在最糟糕情况下需要访问主存储器，并将数据重新传递给LSQ，完成一次存储器读写的全过程。
这里涉及计算机体系结构中的众多术语，比较晦涩难懂，现在对部分术语做简单解释。
·超标量体系结构（Superscalar Architecture）：早期的单发射结构微处理器的流水线设计目标是做到每个周期能平均执行一条指令，但这一目标不能满足处理器性能增长的要求，为了提高处理器的性能，要求处理器具有每个周期能发射执行多条指令的能力。因此超标量体系结构是描述一种微处理器设计理念，它能够在一个时钟周期执行多个指令。
·乱序执行（Out-of-Order Execution）：指CPU采用了允许将多条指令不按程序规定的顺序分开发送给各相应电路单元处理的技术，避免处理器在计算对象不可获取时的等待，从而导致流水线停顿。
·寄存器重命名（Register Rename）：现代处理器的一种技术，用来避免机器指令或者微操作的不必要的顺序化执行，从而提高处理器的指令级并行的能力。它在乱序执行的流水线中有两个作用，一是消除指令之间的寄存器读后写相关（Write-after-Read，WAR）和写后写相关（Write-after-Write，WAW）；二是当指令执行发生例外或者转移指令猜测错误而取消后面的指令时，可用来保证现场的精确。其思路为当一条指令写一个结果寄存器时不直接写到这个结果寄存器，而是先写到一个中间寄存器过渡，当这条指令提交时再写到结果寄存器中。
·分支预测（Branch Predictor）：当处理一个分支指令时，有可能会产生跳转，从而打断流水线指令的处理，因为处理器无法确定该指令的下一条指令，直到分支指令执行完毕。流水线越长，处理器等待时间便越长，分支预测技术就是为了解决这一问题而出现的。因此，分支预测是处理器在程序分支指令执行前预测其结果的一种机制。在ARM中，使用全局分支预测器，该预测器由转移目标缓冲器（Branch Target Buffer，BTB）、全局历史缓冲器（Global History Buffer，GHB）、MicroBTB，以及Return Stack组成。
·指令译码器（Instruction Decode）：指令由操作码和地址码组成。操作码表示要执行的操作性质，即执行什么操作；地址码是操作码执行时的操作对象的地址。计算机执行一条指定的指令时，必须首先分析这条指令的操作码是什么，以决定操作的性质和方法，然后才能控制计算机其他各部件协同完成指令表达的功能，这个分析工作由译码器来完成。例如，Cortex-A57可以支持3路译码器，即同时执行3条指令译码，而Cortex-A9处理器只能同时译码2条指令。
·调度单元（Dispatch）：调度器负责把指令或微操作指令派发到相应的执行单元去执行，例如，Cortex-A9处理器的调度器单元有4个接口和执行单元连接，因此每个周期可以同时派发4条指令。
·ALU算术逻辑单元：ALU是处理器的执行单元，主要是进行算术运算，逻辑运算和关系运算的部件。
·LSQ/LSU部件（Load Store Queue/Unit）：LSQ部件是指令流水线的一个执行部件，其主要功能是将来自CPU的存储器请求发送到存储器子系统，并处理其下存储器子系统的应答数据和消息。4．请简述内存屏障（memory barrier）产生的原因。
程序在运行时的实际内存访问顺序和程序代码编写的访问顺序不一致，会导致内存乱序访问。内存乱序访问的出现是为了提高程序运行时的性能。内存乱序访问主要发生在如下两个阶段。
（1）编译时，编译器优化导致内存乱序访问。
（2）运行时，多CPU间交互引起的内存乱序访问。
编译器会把符合人类思考的逻辑代码（例如C语言）翻译成CPU运算规则的汇编指令，编译器了解底层CPU的思维逻辑，因此它会在翻译成汇编时进行优化。例如内存访问指令的重新排序，提高指令级并行效率。然而，这些优化可能会违背程序员原始的代码逻辑，导致发生一些错误。编译时的乱序访问可以通过barrier（）来规避。
#define barrier（） __asm__ __volatile__ （"" ::："memory"）
barrier（）函数告诉编译器，不要为了性能优化而将这些代码重排。
由于现代处理器普遍采用超标量技术、乱序发射以及乱序执行等技术来提高指令级并行的效率，因此指令的执行序列在处理器的流水线中有可能被打乱，与程序代码编写时序列的不一致。另外现代处理器采用多级存储结构，如何保证处理器对存储子系统访问的正确性也是一大挑战。
例如，在一个系统中含有n个处理器P1～Pn，假设每个处理器包含Si个存储器操作，那么从全局来看可能的存储器访问序列有多种组合。为了保证内存访问的一致性，需要按照某种规则来选出合适的组合，这个规则叫做内存一致性模型（Memory Consistency Model）。这个规则需要保证正确性的前提，同时也要保证多处理器访问较高的并行度。
在一个单核处理器系统中，访问内存的正确性比较简单。每次存储器读操作所获得的结果是最近写入的结果，但是在多处理器并发访问存储器的情况下就很难保证其正确性了。我们很容易想到使用一个全局时间比例部件（Global Time Scale）来决定存储器访问时序，从而判断最近访问的数据。这种内存一致性访问模型是严格一致性（Strict Consistency）内存模型，也称为Atomic Consistency。全局时间比例方法实现的代价比较大，那么退而求其次，采用每一个处理器的本地时间比例部件（Local Time Scale）的方法来确定最新数据的方法被称为顺序一致性内存模型（Sequential Consistency）。处理器一致性内存模型（Processor Consistency）是进一步弱化，仅要求来自同一个处理器的写操作具有一致性的访问即可。
以上这些内存一致性模型是针对存储器读写指令展开的，还有一类目前广泛使用的模型，这些模型使用内存同步指令，也称为内存屏障指令。在这种模型下，存储器访问指令被分成数据指令和同步指令两大类，弱一致性内存模型（weak consistency）就是基于这种思想的。
1986年，Dubois等发表的论文描述了弱一致性内存模型的定义。
·对同步变量的访问是顺序一致的。
·在所有之前的写操作完成之前，不能访问同步变量。
·在所有之前同步变量的访问完成之前，不能访问（读或者写）数据。
弱一致性内存模型要求同步访问是顺序一致的，在一个同步访问可以被执行之前，所有之前的数据访问必须完成。在一个正常的数据访问可以被执行之前，所有之前的同步访问必须完成。这实质上把一致性问题留给了程序员来决定。
ARM的Cortex-A系列处理器实现弱一致性内存模型，同时也提供了3条内存屏障指令。5．ARM有几条memory barrier的指令？分别有什么区别？
从ARMv7指令集开始，ARM提供3条内存屏障指令。